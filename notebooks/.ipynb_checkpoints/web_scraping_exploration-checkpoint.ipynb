{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "URL = 'https://www.indeed.com/jobs?q=data+science&l=Denver%2C+CO#&start=10'\n",
    "\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.text, features='html.parser')\n",
    "\n",
    "# def extract_company_from_result(soup): \n",
    "#   companies = []\n",
    "#   for div in soup.find_all(name=”div”, attrs={“class”:”row”}):\n",
    "#     company = div.find_all(name=”span”, attrs={“class”:”company”})\n",
    "#     if len(company) > 0:\n",
    "#       for b in company:\n",
    "#         companies.append(b.text.strip())\n",
    "#     else:\n",
    "#       sec_try = div.find_all(name=”span”, attrs={“class”:”result-link-source”})\n",
    "#         for span in sec_try:\n",
    "#           companies.append(span.text.strip())\n",
    "#  return(companies)\n",
    " \n",
    "df = pd.DataFrame()\n",
    "\n",
    "def extract_company_from_result(soup):\n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class': 'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class': 'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return companies\n",
    "\n",
    "\n",
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return jobs\n",
    "\n",
    "# def extract_title_company(soup):\n",
    "#     companies = []\n",
    "#     jobs = []\n",
    "#     for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "#         company = div.find_all(name='span', attrs={'class': 'company'})\n",
    "#         if len(company) > 0:\n",
    "#             for b in company:\n",
    "#                 companies.append(b.text.strip())\n",
    "#     for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "#         for a in div.find_all(name='a', attrs={'data-tn-element': 'jobTitle'}):\n",
    "#             jobs.append(a['title'])\n",
    "#     return companies, jobs\n",
    "\n",
    "    \n",
    "def extract_locations_from_results(soup):\n",
    "    locations = []\n",
    "    for div in soup.find_all('div', attrs={'class': 'recJobLoc'}):\n",
    "        loc = div['data-rc-loc']\n",
    "        locations.append(loc)\n",
    "    return locations\n",
    "\n",
    "def extract_title_company_location(soup):\n",
    "    jobs = extract_job_title_from_result(soup)\n",
    "    companies = extract_company_from_result(soup)\n",
    "    locations = extract_locations_from_results(soup)\n",
    "    return jobs, companies, locations\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jobs</th>\n",
       "      <th>Companies</th>\n",
       "      <th>Locations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Data Science Modeler</td>\n",
       "      <td>Avero</td>\n",
       "      <td>Boulder, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Jr. Big Data Engineer</td>\n",
       "      <td>Enhance IT</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Aegis Premier Technologies</td>\n",
       "      <td>Westminster, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Valen Analytics</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sr Business Analyst / Data Scientist</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Valen Analytics</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Data Science Analyst</td>\n",
       "      <td>Payfone</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Pricesenz</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Maxar Technologies</td>\n",
       "      <td>Westminster, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Data Science Journalist</td>\n",
       "      <td>Alteryx, Inc.</td>\n",
       "      <td>Broomfield, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Arrow Electronics, Inc.</td>\n",
       "      <td>Centennial, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Deloitte</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Head of Data Science</td>\n",
       "      <td>Frontdoor</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dataiku</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Nexthealth</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The18</td>\n",
       "      <td>Boulder, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Data Warehouse Engineer</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Denver, CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Jobs                   Companies  \\\n",
       "0                   Data Science Modeler                       Avero   \n",
       "1                  Jr. Big Data Engineer                  Enhance IT   \n",
       "2                         Data Scientist  Aegis Premier Technologies   \n",
       "3                         Data Scientist        Willis Towers Watson   \n",
       "4                         Data Scientist             Valen Analytics   \n",
       "5   Sr Business Analyst / Data Scientist                     PHOENIX   \n",
       "6                          Data Engineer             Valen Analytics   \n",
       "7                   Data Science Analyst                     Payfone   \n",
       "8                         Data Scientist                   Pricesenz   \n",
       "9                    Data Science Intern          Maxar Technologies   \n",
       "10               Data Science Journalist               Alteryx, Inc.   \n",
       "11                   Data Science Intern     Arrow Electronics, Inc.   \n",
       "12                        Data Scientist                    Deloitte   \n",
       "13                  Head of Data Science                   Frontdoor   \n",
       "14                        Data Scientist                     Dataiku   \n",
       "15                 Senior Data Scientist                  Nexthealth   \n",
       "16                        Data Scientist                       The18   \n",
       "17               Data Warehouse Engineer              Seen by Indeed   \n",
       "18                         Data Engineer              Seen by Indeed   \n",
       "\n",
       "          Locations  \n",
       "0       Boulder, CO  \n",
       "1        Denver, CO  \n",
       "2   Westminster, CO  \n",
       "3        Denver, CO  \n",
       "4        Denver, CO  \n",
       "5        Denver, CO  \n",
       "6        Denver, CO  \n",
       "7        Denver, CO  \n",
       "8    Broomfield, CO  \n",
       "9   Westminster, CO  \n",
       "10   Broomfield, CO  \n",
       "11   Centennial, CO  \n",
       "12       Denver, CO  \n",
       "13       Denver, CO  \n",
       "14       Denver, CO  \n",
       "15       Denver, CO  \n",
       "16      Boulder, CO  \n",
       "17       Denver, CO  \n",
       "18       Denver, CO  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs, companies, locations = extract_title_company_location(soup)\n",
    "df = pd.DataFrame()\n",
    "df['Jobs'] = jobs\n",
    "df['Companies'] = companies\n",
    "df['Locations'] = locations\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comp, job in zip(companies, jobs):\n",
    "    print(f'job: {job}')\n",
    "    print(f'company: {comp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Companies'] = companies\n",
    "df['Jobs'] = jobs\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_url = 'https://www.indeed.com/jobs?q=data+science&l=Denver%2C+CO&limit=50&radius=25'\n",
    "cont_url = 'https://www.indeed.com/jobs?q=data+science&l=Denver%2C+CO&limit=50&radius=25&start='\n",
    "start = [num for num in range(50, 251, 50)]\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [starting_url]\n",
    "for i in start:\n",
    "    base_url = starting_url\n",
    "    addition = f'&start={i}'\n",
    "    base_url += addition\n",
    "    url_list.append(base_url)\n",
    "    \n",
    "url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies, jobs = [], []\n",
    "for url in url_list:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, features='html.parser')\n",
    "    companies_temp, job_temp = extract_title_company(soup)\n",
    "    companies.extend(companies_temp)\n",
    "    jobs.extend(job_temp)\n",
    "    time.sleep(5)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Jobs'] = jobs\n",
    "df['Companies'] = companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title_company(soup):\n",
    "    companies = []\n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "        company = div.find(name='span', attrs={'class': 'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "    for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element': 'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return companies, jobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_title_company(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://www.indeed.com/jobs?q=data+science&l=Denver%2C+CO&limit=50&radius=25'\n",
    "\n",
    "page = requests.get(url2)\n",
    "soup = BeautifulSoup(page.text, features='lxml')\n",
    "\n",
    "soup.find_all('div', attrs={'class': 'jobsearch-SerpJobCard unifiedRow row Result clickcard'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find_all('div', attrs={'class': 'sjcl'}):\n",
    "    print(soup.find('div', attrs={'class': 'recJobLoc'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for div in soup.find_all('div', attrs={'class': 'recJobLoc'}):\n",
    "    print(div['data-rc-loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/josh-mantovani/Desktop\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_company_from_result(soup):\n",
    "    companies = []\n",
    "    for div in soup.find_all(name='div', attrs={'class': 'row'}):\n",
    "        company = div.find_all(name='span', attrs={'class': 'company'})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name='span', attrs={'class': 'result-link-source'})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    return companies\n",
    "\n",
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name='div', attrs={'class':'row'}):\n",
    "        for a in div.find_all(name='a', attrs={'data-tn-element':'jobTitle'}):\n",
    "            jobs.append(a['title'])\n",
    "    return jobs\n",
    "\n",
    "def extract_locations_from_results(soup):\n",
    "    locations = []\n",
    "    for div in soup.find_all('div', attrs={'class': 'recJobLoc'}):\n",
    "        loc = div['data-rc-loc']\n",
    "        locations.append(loc)\n",
    "    return locations\n",
    "\n",
    "def extract_comprating_from_results(soup):\n",
    "    ratings = []\n",
    "    for div in soup.find_all('div', attrs={'class': 'sjcl'}):\n",
    "        span = div.find('span', attrs={'class': 'ratingsContent'})\n",
    "        if span:\n",
    "            rating = span.text.strip()\n",
    "            ratings.append(float(rating))\n",
    "        else:\n",
    "            ratings.append(None)\n",
    "    return ratings\n",
    "\n",
    "def extract_easyapply_from_results(soup):\n",
    "    easy_apply = []\n",
    "    for div in soup.find_all('div', attrs={'class': 'row'}):\n",
    "        if div.find('span', attrs={'class': 'iaLabel'}):\n",
    "            easy_apply.append('Easy Apply')\n",
    "        elif div.find('span', attrs={'class': 'iaLabel'}) == None:\n",
    "            easy_apply.append('Not Easy Apply')\n",
    "    return easy_apply\n",
    "\n",
    "def extract_title_company_location_ea(soup):\n",
    "    jobs = extract_job_title_from_result(soup)\n",
    "    companies = extract_company_from_result(soup)\n",
    "    locations = extract_locations_from_results(soup)\n",
    "    easy_apply = extract_easyapply_from_results(soup)\n",
    "    ratings = extract_comprating_from_results(soup)\n",
    "    return jobs, companies, locations, easy_apply, ratings\n",
    "\n",
    "def get_last_page(URL):\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.text, features='lxml')\n",
    "    pn_list = []\n",
    "    for pn in soup.find_all('span', attrs={'class': 'pn'}):\n",
    "        page_number = list(pn.text)\n",
    "        pn_list.append(page_number)\n",
    "    if len(pn_list[-2]) > 1:\n",
    "        last_page = int(pn_list[-2][0] + pn_list[-2][1])\n",
    "    else:\n",
    "        last_page = int(pn_list[-2][0])\n",
    "    return last_page\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6, None, 4.0, None, None, None, None, 3.7, None, None, 3.5, 4.0, 4.1, 3.7, 4.6, 3.7, None, None, 4.0, None, 3.0, 4.3, None, 4.0, 4.0, 3.2, None, None, 3.9, None, None, None, 3.7, None, 4.5, 4.0, None, 4.2, None, 3.9, None, 3.8, 3.8, 3.5, 3.9, None, None, 4.1, None, 3.3, 4.6, 3.9, None, 3.5, None, None, 4.4, 3.6, 3.9]\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://www.indeed.com/jobs?q=data+science&l=Denver,+CO&limit=50&radius=25'\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.text, features='lxml')\n",
    "print(extract_comprating_from_results(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_url_list(starting_url):\n",
    "    last_page = get_last_page(starting_url)\n",
    "    ending_range = (last_page - 1) * 50\n",
    "    start = [num for num in range(50, ending_range + 1, 50)]\n",
    "    url_list = [starting_url]\n",
    "    for i in start:\n",
    "        base_url = starting_url\n",
    "        page_num = f'&start={i}'\n",
    "        base_url += page_num\n",
    "        url_list.append(base_url)\n",
    "    return url_list\n",
    "\n",
    "def pull_jobs_comp_loc_allpages(url):\n",
    "    url_list = get_url_list(url)\n",
    "    companies = []\n",
    "    jobs = []\n",
    "    locations = []\n",
    "    easy_apply = []\n",
    "    ratings = []\n",
    "    for url in url_list:\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.text, features='html.parser')\n",
    "        jobs_temp, companies_temp, locations_temp, easy_apply_temp, ratings_temp = extract_title_company_location_ea(soup)\n",
    "        companies.extend(companies_temp)\n",
    "        jobs.extend(jobs_temp)\n",
    "        locations.extend(locations_temp)\n",
    "        easy_apply.extend(easy_apply_temp)\n",
    "        ratings.extend(ratings_temp)\n",
    "        time.sleep(2)\n",
    "    return companies, jobs, locations, easy_apply, ratings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Easy_Apply</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Avero</td>\n",
       "      <td>Data Science Modeler</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Seen by Indeed</td>\n",
       "      <td>Data Warehouse Engineer</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Valen Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>Valen Analytics</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>332</td>\n",
       "      <td>Valen Analytics</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>UPMC</td>\n",
       "      <td>Director Integrated Data Science</td>\n",
       "      <td>Loveland, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>334</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>Sr Business Analyst / Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Easy Apply</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company_Name                             Job_Title      Location  \\\n",
       "0                   Avero                  Data Science Modeler   Boulder, CO   \n",
       "1          Seen by Indeed                         Data Engineer    Denver, CO   \n",
       "2    Willis Towers Watson                        Data Scientist    Denver, CO   \n",
       "3          Seen by Indeed               Data Warehouse Engineer    Denver, CO   \n",
       "4         Valen Analytics                        Data Scientist    Denver, CO   \n",
       "..                    ...                                   ...           ...   \n",
       "331       Valen Analytics                        Data Scientist    Denver, CO   \n",
       "332       Valen Analytics                         Data Engineer    Denver, CO   \n",
       "333                  UPMC      Director Integrated Data Science  Loveland, CO   \n",
       "334               PHOENIX  Sr Business Analyst / Data Scientist    Denver, CO   \n",
       "335  Willis Towers Watson                        Data Scientist    Denver, CO   \n",
       "\n",
       "         Easy_Apply  Rating  \n",
       "0    Not Easy Apply     2.6  \n",
       "1        Easy Apply     NaN  \n",
       "2    Not Easy Apply     3.7  \n",
       "3    Not Easy Apply     NaN  \n",
       "4    Not Easy Apply     NaN  \n",
       "..              ...     ...  \n",
       "331  Not Easy Apply     NaN  \n",
       "332  Not Easy Apply     NaN  \n",
       "333  Not Easy Apply     3.7  \n",
       "334      Easy Apply     NaN  \n",
       "335  Not Easy Apply     3.7  \n",
       "\n",
       "[336 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "starting_url = 'https://www.indeed.com/jobs?q=data+science&l=CO&limit=50&radius=25'\n",
    "\n",
    "companies, jobs, locations, easy_apply, ratings = pull_jobs_comp_loc_allpages(starting_url)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Company_Name'] = companies\n",
    "df['Job_Title'] = jobs\n",
    "df['Location'] = locations\n",
    "df['Easy_Apply'] = easy_apply\n",
    "df['Rating'] = ratings\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_nullrating = df[df['Rating'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Easy_Apply</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Software Engineer - Site Reliability Engineer ...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>307</td>\n",
       "      <td>Global Resource Solutions</td>\n",
       "      <td>Cyber Security Data Scientist</td>\n",
       "      <td>Colorado Springs, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>308</td>\n",
       "      <td>Spectrum</td>\n",
       "      <td>Network Engineer II - Data Center</td>\n",
       "      <td>Greenwood Village, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>Leidos</td>\n",
       "      <td>Data Engineer with TS/SCI with Poly</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>Manager, Big Data Software Engineer</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>CDW</td>\n",
       "      <td>Associate Consulting Engineer – Federal (Data ...</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>312</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Englewood, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>313</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Senior Engineer – Mission Data Analysis Engine...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315</td>\n",
       "      <td>HERE Technologies</td>\n",
       "      <td>Lead Software Engineer - Machine Learning</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Spacecraft Command and Data Handling (C D H) E...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>Hewlett Packard Enterprise</td>\n",
       "      <td>Senior Solutions Engineer – Big Data</td>\n",
       "      <td>Fort Collins, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>Jacobs</td>\n",
       "      <td>Big Data Systems Design Engineer IRES - SAFB</td>\n",
       "      <td>Schriever AFB, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322</td>\n",
       "      <td>LOCKHEED MARTIN CORPORATION</td>\n",
       "      <td>Electronics Engineer, Command and Data Handlin...</td>\n",
       "      <td>Littleton, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>323</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Senior Electrical Engineer-Spacecraft Command ...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>324</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Principal Electrical Engineer-Spacecraft Comma...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Electrical Engineer II-Spacecraft Command &amp; Da...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326</td>\n",
       "      <td>Ball Aerospace</td>\n",
       "      <td>Senior Electrical Engineer-Spacecraft Command ...</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>328</td>\n",
       "      <td>Avero</td>\n",
       "      <td>Data Science Modeler</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333</td>\n",
       "      <td>UPMC</td>\n",
       "      <td>Director Integrated Data Science</td>\n",
       "      <td>Loveland, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>Willis Towers Watson</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>Not Easy Apply</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Company_Name  \\\n",
       "306                      Twitter   \n",
       "307    Global Resource Solutions   \n",
       "308                     Spectrum   \n",
       "309                       Leidos   \n",
       "310                         KPMG   \n",
       "311                          CDW   \n",
       "312                      Comcast   \n",
       "313               Ball Aerospace   \n",
       "315            HERE Technologies   \n",
       "319               Ball Aerospace   \n",
       "320   Hewlett Packard Enterprise   \n",
       "321                       Jacobs   \n",
       "322  LOCKHEED MARTIN CORPORATION   \n",
       "323               Ball Aerospace   \n",
       "324               Ball Aerospace   \n",
       "325               Ball Aerospace   \n",
       "326               Ball Aerospace   \n",
       "328                        Avero   \n",
       "333                         UPMC   \n",
       "335         Willis Towers Watson   \n",
       "\n",
       "                                             Job_Title               Location  \\\n",
       "306  Software Engineer - Site Reliability Engineer ...            Boulder, CO   \n",
       "307                      Cyber Security Data Scientist   Colorado Springs, CO   \n",
       "308                  Network Engineer II - Data Center  Greenwood Village, CO   \n",
       "309                Data Engineer with TS/SCI with Poly             Aurora, CO   \n",
       "310                Manager, Big Data Software Engineer             Denver, CO   \n",
       "311  Associate Consulting Engineer – Federal (Data ...             Denver, CO   \n",
       "312                               Senior Data Engineer          Englewood, CO   \n",
       "313  Senior Engineer – Mission Data Analysis Engine...            Boulder, CO   \n",
       "315          Lead Software Engineer - Machine Learning            Boulder, CO   \n",
       "319  Spacecraft Command and Data Handling (C D H) E...            Boulder, CO   \n",
       "320               Senior Solutions Engineer – Big Data       Fort Collins, CO   \n",
       "321       Big Data Systems Design Engineer IRES - SAFB      Schriever AFB, CO   \n",
       "322  Electronics Engineer, Command and Data Handlin...          Littleton, CO   \n",
       "323  Senior Electrical Engineer-Spacecraft Command ...            Boulder, CO   \n",
       "324  Principal Electrical Engineer-Spacecraft Comma...            Boulder, CO   \n",
       "325  Electrical Engineer II-Spacecraft Command & Da...            Boulder, CO   \n",
       "326  Senior Electrical Engineer-Spacecraft Command ...            Boulder, CO   \n",
       "328                               Data Science Modeler            Boulder, CO   \n",
       "333                   Director Integrated Data Science           Loveland, CO   \n",
       "335                                     Data Scientist             Denver, CO   \n",
       "\n",
       "         Easy_Apply  Rating  \n",
       "306  Not Easy Apply     4.1  \n",
       "307  Not Easy Apply     3.9  \n",
       "308  Not Easy Apply     3.5  \n",
       "309  Not Easy Apply     3.8  \n",
       "310  Not Easy Apply     4.0  \n",
       "311  Not Easy Apply     3.7  \n",
       "312  Not Easy Apply     3.7  \n",
       "313  Not Easy Apply     3.8  \n",
       "315  Not Easy Apply     3.8  \n",
       "319  Not Easy Apply     3.8  \n",
       "320  Not Easy Apply     3.7  \n",
       "321  Not Easy Apply     3.9  \n",
       "322  Not Easy Apply     4.1  \n",
       "323  Not Easy Apply     3.8  \n",
       "324  Not Easy Apply     3.8  \n",
       "325  Not Easy Apply     3.8  \n",
       "326  Not Easy Apply     3.8  \n",
       "328  Not Easy Apply     2.6  \n",
       "333  Not Easy Apply     3.7  \n",
       "335  Not Easy Apply     3.7  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_not_nullrating.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/pagead/clk?mo=r&ad=-6NYlbfkN0BfIQYuIlFPJvCnPBPfsjtoOKkm6zQOy3MTdZ7WA9rSinzkt5GqabLNhPeV3rUS-1SOlpO76q1CnbH6t2gxdZElnamMfnWgBOSMNNqvicz5nTJ4LpHWwLqYmVXBax_v8kEvQ53tM5QALSLcATjLSHd4O1a07UOTKMG1WRjOQvpqUYMzVRyXZGo9RWTYPxZ0iyY5e1NZAHuiZgFZFhdvgp0-jhr-NxG80P6nucEOQUo7Y0EwyDK5fhHvro_Av5wVlm6DTnCg3hNvJ5udCA-nuE-IT70IAeLB_q-x-DV2DJb-uD1p7WOqzfUrCexZP8TArY9klmDXsNb7EP_1C6qdKdfYYFqbj8NyYqDdViylpP1KenAv9YF138N98t_ORLWs8HUTXyLGI4ghRuaQyov4tfIllHI6ixM3KrfHg5LeDEti0Qq0esG-__oB&p=0&fvj=0&vjs=3'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = []\n",
    "for div in soup.find_all('div', attrs={'class': 'row'}):\n",
    "    for a in div.find_all('a', attrs={'target': '_blank'}):\n",
    "        links.append(a['href'])\n",
    "    \n",
    "links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0BfIQYuIlFPJvCnPBPfsjtoOKkm6zQOy3MTdZ7WA9rSinzkt5GqabLNhPeV3rUS-1SOlpO76q1CnbH6t2gxdZElnamMfnWgBOSMNNqvicz5nTJ4LpHWwLqYmVXBax_v8kEvQ53tM5QALSLcATjLSHd4O1a07UOTKMG1WRjOQvpqUYMzVRyXZGo9RWTYPxZ0iyY5e1NZAHuiZgFZFhdvgp0-jhr-NxG80P6nucEOQUo7Y0EwyDK5fhHvro_Av5wVlm6DTnCg3hNvJ5udCA-nuE-IT70IAeLB_q-x-DV2DJb-uD1p7WOqzfUrCexZP8TArY9klmDXsNb7EP_1C6qdKdfYYFqbj8NyYqDdViylpP1KenAv9YF138N98t_ORLWs8HUTXyLGI4ghRuaQyov4tfIllHI6ixM3KrfHg5LeDEti0Qq0esG-__oB&p=0&fvj=0&vjs=3\n"
     ]
    }
   ],
   "source": [
    "final_links = []\n",
    "for link in links:\n",
    "    final_link = 'indeed.com' + link\n",
    "    final_links.append(final_link)\n",
    "    \n",
    "print(final_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
